[
  {
    "objectID": "03-statistical-inference.html",
    "href": "03-statistical-inference.html",
    "title": "3  Drawing inference from statistical models, and statistical power",
    "section": "",
    "text": "3.1 Method\nWe simulated a population of possible values and then drew random samples, calculated statistics and interpreted them. The population of values was regarded as the possible difference between two treatments in a cross-over study where participants performed both treatments. The values in the population were calculated as Treatment - Control. We simulated a population of one million numbers with a mean of 1.5 and a standard deviation of 3. We then made two different set of studies, one set with a sample size of 8 (samp1) and one set with a sample size of 40 (samp2). Additionally, we estimated the average value of the population.\nCall:\nlm(formula = y ~ 1, data = samp1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.5322 -1.2523 -0.0883  1.3540  4.8692 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)    1.840      1.251    1.47    0.185\n\nResidual standard error: 3.539 on 7 degrees of freedom\n\n\n\nCall:\nlm(formula = y ~ 1, data = samp2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.6557 -2.2883  0.2636  2.2549  6.4212 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   1.5642     0.4774   3.276  0.00221 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.019 on 39 degrees of freedom\nHere we drew two random samples corresponding sample sizes of 8 and 40 and saved this data in data frames with the dependent variable y. Then the model were fitted as a linear model and saved as a model object. Object m1 corresponds to a sample size of 8, while m2 corresponds to a sample size of 40. Our null hypothesis is that there is no difference between the two treatments.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Drawing inference from statistical models, and statistical power</span>"
    ]
  },
  {
    "objectID": "03-statistical-inference.html#results",
    "href": "03-statistical-inference.html#results",
    "title": "3  Drawing inference from statistical models, and statistical power",
    "section": "3.2 Results",
    "text": "3.2 Results\n\n3.2.1 Explain the estimate, SE, t-value, and p-value from the regression models that we created previously (m1 and m2).\nIn our model, the estimate represents the mean of the differences between the two treatments in the cross-over study. In model m1, the estimate is 1.84. This means that the average difference between the two treatments for the sample of 8 participants is 1.84. In model m2, the estimate is 1.5642, meaning that the average difference between the two treatments for the sample of 40 participants is a little lower than for the sample of 8. Furthermore, the standard error (SE) provides an estimate of how much variability we expect in the sample mean if we were to repeatedly draw samples of the same size from the population. It is calculated as the sample’s standard deviation (SD) divided by the square root of the sample size. In m1, the standard error (SE) is 1.251, which tells us how much the sample mean of 1.84 might vary if we were to repeat the study multiple times with a sample size of 8. In m2, the standard error is 0.4774 indicating that the sample size of 40 participants gives us a more precise estimate of the population mean. The t-value is a ratio that compares the difference between the sample mean (estimate), and the null hypothesis relative to the standard error (SE). In m1, the t.value is 1.47, meaning the observed mean difference (1.84) is 1.47 standard errors away from the null hypothesis value of 0. The t.value for m2 is almost three times bigger as it is 3.276 indicating that the observed mean difference (0.4774) is 3.276 standard errors away from the null hypothesis. Lastly, the p-value tells us the probability of observing a t-value as extreme (or more extreme) than the one calculated, assuming the null hypothesis is true (i.e., no difference between treatments). In m1, the p-value is 0.185, meaning that there is an 18.5% chance of observing a difference of 1.84 or more if the true difference between the treatments was zero. Since this p-value is above the conventional threshold of 0.05, we fail to reject the null hypothesis, suggesting that the observed difference is not statistically significant. In m2, the p-value is 0.00221, meaning that there is an 0.221% chance of observing a difference of 1.5642 or more if the true difference between the treatments was zero. In comparison to m1, this p-value is below the conventional threshold of 0.05. We therefore reject the null hypothesis, suggesting that the observed difference is statistically significant and there is evidence that the means differ.\n\n\n3.2.2 Discuss what contributes to the different results in the two studies (m1 and m2).\nThe two studies differ primarily in sample size, where m2 have 5 times more participants than m1. Since m1 have a small sample, the mean might fluctuate more due to random variation, whereas larger samples (m2) tend to provide a more stable and reliable estimate closer to the true population mean (Faber and Fonseca 2014). Furthermore, the larger the sample size, the smaller is the standard error, which means a more precise estimate of the population mean (Faber and Fonseca 2014). In m2, the larger sample size leads to a smaller standard error (0.4774), which reduces the uncertainty around the estimate and increases the power of the test to detect differences. The t-value is influenced by both the estimate and the standard error. Even if the estimates are somewhat similar, the smaller standard error in m2 results in a larger t-value, making it more likely to detect a significent effect. Additionally, the p-value depends on the t-value. With a larger sample size, as in m2, the t-value is typically larger, leading to a smaller p-value.This means that m2 is more likely to detect significant differences than m1, where the small sample size leads to a higher p-value and lower statistical power. In conclusion, the larger sample size in m2 leads to a more precise estimate, a smaller standard error, a higher t-value, and ultimately a smaller p-value, increasing the likelihood of detecting a significant difference between the treatments.\n\n\n3.2.3 Why do we use the shaded area in the lower and upper tail of the t-distribution.\nThe shaded area in the lower and upper tail of the t-distribution represents the probability of observing extreme values (both high and low) of the t-value under the null hypothesis. This area helps us determine the p-value, which tells us how likely it is that our observed data could occur by random chance if the null hypothesis is true.\nThe total shaded area in both tails represents the combined probability of observing a t-value as extreme as the one calculated, assuming the null hypothesis is true. The p-value for m1 where 0.185, meaning that 18.5% of the area is in the combined tails, representing the threshold for statistical significance.\n\n\n3.2.4 Calculate the standard deviation of the estimate variable, and the average of the se variable for each of the study sample sizes (8 and 40). Explain why these numbers are very similar. How can you define the Standard Error (SE) in light of these calculations?\nBy calculating the standard deviation of the estimates across the 1000 studies we get a measure of how much the sample means fluctuate between different samples of the same size. For the smaller sample size of 8, the standard deviation comes out to be 1.0708432, while for the bigger sample size of 40 it comes out to be 0.4838475. Furthermore, the average standard error represents the average uncertainty of the sample mean estimate in each study. It reflects the variability in the sample means and depends on the sample size. The average standard error for the smaller sample size is 1.0213745, and 0.4696954 for the bigger sample size. Why are these numbers very similar? The standard deviation of the estimates and the average standard error are conceptually related, as the standard error estimates how much the sample mean might vary from the population mean. They are both measures of variability, but while standard error (SE) is an estimate based on the sample, the standard deviation of the estimates shows the actual observed variation across multiple studies. Therefore, in light of these calculations, we can define standard error (SE) as the expected variability from sample to sample.\n\n\n3.2.5 Create a histogram of the p-values from each study sample-size. How do you interpret these histograms, what do they tell you about the effect of sample size on statistical power?\n\n\n\n\n\n\n\n\n\nFor sample size 8, the p-values are more spread out, with many values above the significance threshold of 0.05. This indicates that with a smaller sample, there is lower statistical power, and many studies fail to detect a statistically significant difference. For sample size 40, the p-values are more concentrated towards lower values, indicating that a larger sample size increases the likelihood of detecting significant effects. This reflects increased statistical power with larger sample sizes, meaning the test is more likely to reject the null hypothesis when a true effect exists.\n\n\n3.2.6 Calculate the number of studies from each sample size that declare a statistical significant effect.\n\n\n# A tibble: 2 × 2\n      n sig_results\n  &lt;dbl&gt;       &lt;dbl&gt;\n1     8       0.227\n2    40       0.865\n\n\nWhen calculating the number of studies that declare a statistical significant effect we find that fewer studies (0.227) are likely to reach statistical significance in the sample size of 8. This is because of the low statistical power associated with small samples. In the sample size of 40, more studies (0.865) will show a significant effect due to the higher power of larger samples, making it easier to detect true differences.\n\n\n3.2.7 Using the pwr package, calculate the power of a one-sample t-test, with a effect size of 1.5/3, your specified significance level and sample sizes 8 and 40. Explain the results in the light of your simulations.\n\n\n\n     One-sample t test power calculation \n\n              n = 8\n              d = 0.5\n      sig.level = 0.05\n          power = 0.232077\n    alternative = two.sided\n\n\n\n     One-sample t test power calculation \n\n              n = 40\n              d = 0.5\n      sig.level = 0.05\n          power = 0.8693981\n    alternative = two.sided\n\n\nTo calculate the power of a one-sample t-test, we use the effect size 𝑑 = 𝜇/𝜎, where 𝜇 = 1.5 (mean) and σ = 3 (standard deviation). The effect size 𝑑 = 1.5/3 = 0.5. For a sample size of 8 we find that the power will be relatively low, 0.232077, reflecting that with smaller samples, we have a lower chance of detecting a true effect when it exists (Faber and Fonseca 2014). This corresponds to fewer studies achieving significance in the simulation. For a sample size of 40 we find that the power will be much higher, 0.8693981, indicating that with a larger sample size, we have a higher chance of detecting a true effect. This explains why more studies with sample size 40 declare significance in the simulation.\nWe will now simulate a population without differences between treatment and control. The code below is very similar to the one we use above, except that we use an average effect of 0 in the population.\n\n\n\n\n\n\n\n\n\n\n\n3.2.8 With a significance level of 5%, how many studies would give you a “false positive” result if you did many repeated studies?\nTo determine how many studies would give a “false positive” result with a significance level of 5%, we calculate how many studies produce a p-value less than 0.05 in this simulation. Since the population mean is set to 0 any p-value below 0.05 in this scenario would represent a false positive. For the sample size of 8 we got 44 while for the sample size of 40 we got 49. With a significance level of 5%, we expect roughly 5% of the 1000 studies to produce p-values below 0.05 due to random variation, even though the null hypothesis is true. For 1000 studies, this means we expect around 50 false positive results for each sample size. The actual number of false positives may vary slightly due to the randomness in the simulation but should be close to 50 for each sample size (8 and 40).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Drawing inference from statistical models, and statistical power</span>"
    ]
  },
  {
    "objectID": "06-vitenskapsteori.html",
    "href": "06-vitenskapsteori.html",
    "title": "6  Philosophy of science",
    "section": "",
    "text": "See instructions on canvas.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Philosophy of science</span>"
    ]
  },
  {
    "objectID": "07-laboratory-report.html",
    "href": "07-laboratory-report.html",
    "title": "7  Molecular Laboratory report",
    "section": "",
    "text": "Select one laboratory assignment and write a detailed report.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Molecular Laboratory report</span>"
    ]
  },
  {
    "objectID": "03-statistical-inference.html#conclusion",
    "href": "03-statistical-inference.html#conclusion",
    "title": "3  Drawing inference from statistical models, and statistical power",
    "section": "3.3 Conclusion",
    "text": "3.3 Conclusion\nIn this study, we explored the impact of sample size on statistical results by conducting simulations across different study sizes (8 and 40 participants). We observed that larger sample sizes lead to more precise estimates, lower standard errors, and increased t-values, resulting in a higher likelihood of detecting statistically significant effects. On the other hand, smaller sample sizes had higher variability in estimates and standard errors, contributing to lower statistical power and fewer significant results. Our findings also emphasize the importance of sample size in improving the reliability of statistical tests, as demonstrated by the power calculations. Larger samples provide greater statistical power, allowing for more accurate detection of true effects while maintaining the expected false positive rate under the null hypothesis. Overall, this simulation highlights how increased sample sizes lead to more robust and reliable conclusions in research.\n\n\n\n\nFaber, Jorge, and Lilian Martins Fonseca. 2014. “How Sample Size Influences Research Outcomes.” Dental Press Journal of Orthodontics 19 (4): 27–29. https://doi.org/10.1590/2176-9451.19.4.027-029.ebo.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Drawing inference from statistical models, and statistical power</span>"
    ]
  },
  {
    "objectID": "02-regression-models.html",
    "href": "02-regression-models.html",
    "title": "2  Rapport 2",
    "section": "",
    "text": "3 Predikere data ved hjelp av regresjon",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rapport 2</span>"
    ]
  },
  {
    "objectID": "02-regression-models.html#introduksjon",
    "href": "02-regression-models.html#introduksjon",
    "title": "2  Rapport 2",
    "section": "3.1 Introduksjon",
    "text": "3.1 Introduksjon\nHensikten med denne rapporten er å predikere data ved hjelp av regresjon gjort i Rstudio, samt tolke en regresjonstabell. Rapporten inneholder tre deler. Ved å bestemme laktatterskel ved blodlaktatverdiene 2 og 4 mmol L-1 analyserer vi forholdet mellom prestasjon i watt og treningsintensitet. Vi analyserte hellningen til en qPCR kalibreringskurve, og tolket en regresjonstabell om forholdet mellom 3RM squat og tverrsnittsareal til type II muskelfibrer.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rapport 2</span>"
    ]
  },
  {
    "objectID": "02-regression-models.html#metode",
    "href": "02-regression-models.html#metode",
    "title": "2  Rapport 2",
    "section": "3.2 Metode",
    "text": "3.2 Metode\n\n3.2.1 Del 1: Predikert laktatterskel\nI del 1 av rapporten ble datasettet cyclingstudy fra (Sylta et al. 2016) brukt til å predikere to bestemte blodlaktatterskler ved 2 og 4 mmol L-1. Behandlingen av dataen ble gjort i (Posit team 2024).\n\n\n3.2.2 Del 2: Predikert hellning på qPCR kalibreringskurve\nI del 2 av rapporten har vi ved hjelp av (Schindelin et al. 2012) analysert et bilde av qPCR som ble hentet fram fra forsøket (“Login - eLabFTW — Elab.inn.no”). Analysen av bildet gav oss data som vi anvendte i (Posit team 2024) for å predikere hellningen til qPCR kalibreringskurven.\n\n\n3.2.3 Del 3: Tolke en regresjonstabell\nI del 3 av rapporten har vi gjort en statistisk analyse av forholdet mellom “Type II (FAST) fibers cross sectional area (micrometer2)” ved baseline (FAST_CSA_T1) og “Squat 3 repetition maximum load (kg)” ved baseline (SQUAT_3RM) fra datasettet til (Haun et al. 2018) og (Haun et al. 2019) for å undersøke om det var et linjert forhold.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rapport 2</span>"
    ]
  },
  {
    "objectID": "02-regression-models.html#resultat",
    "href": "02-regression-models.html#resultat",
    "title": "2  Rapport 2",
    "section": "3.3 Resultat",
    "text": "3.3 Resultat\n\n3.3.1 Del 1: Predikert laktatterskel\n\n\nCode\nlibrary(tidyverse)\nlibrary(exscidata)\n\ndata(\"cyclingstudy\")\n\ncyclingstudy %&gt;%\n  # Select columns needed for analysis\n  select(subject, group, timepoint, lac.125:lac.375) %&gt;%\n  # Only one participant and time-point\n  filter(timepoint == \"pre\", subject == 3) %&gt;%\n  # Pivot to long format data using the lactate columns\n  pivot_longer(names_to = \"watt\", \n               values_to = \"lactate\", \n               names_prefix = \"lac.\",\n               names_transform = list(watt = as.numeric),\n               cols = lac.225:lac.375) %&gt;%\n  # Plot the data, group = subject needed to connect the points\n  ggplot(aes(watt, lactate, group = subject))  + \n  geom_line(lty = 2) +\n  geom_point(shape = 23, fill = \"pink\", size = 3) +\n  labs(caption = \"Figure 2.1:Relationship between workload (watt) and lactate\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(exscidata)\n\ndata(\"cyclingstudy\")\n\ncyclingstudy %&gt;%\n  # Select columns needed for analysis\n  select(subject, group, timepoint, lac.125:lac.375) %&gt;%\n  # Only one participant and time-point\n  filter(timepoint == \"pre\", subject == 3) %&gt;%\n  # Pivot to long format data using the lactate columns\n  pivot_longer(names_to = \"watt\", \n               values_to = \"lactate\", \n               names_prefix = \"lac.\",\n               names_transform = list(watt = as.numeric),\n               cols = lac.225:lac.375) %&gt;%\n  # Plot the data, group = subject needed to connect the points\n  ggplot(aes(watt, lactate, group = subject))  + \n  geom_line(lty = 2) +\n  geom_point(shape = 23, fill = \"pink\", size = 2) +\n  # Adding straight lines at specific values\n   geom_hline(yintercept = 2, color = \"deepskyblue\") +\n  geom_vline(xintercept = 273.3, color = \"deepskyblue\") + \n  labs(caption = \"Figure 2.2: Estimated exercise intensity at 2 mmol L^-1^ \")\n\n\n\n\n\n\n\n\n\n\n  #| warning: FALSE\n#| message: FALSE\n#| code-fold: true\n#| name: \"figure 2.3\"\n\nlibrary(tidyverse)\nlibrary(exscidata)\n\ndata(\"cyclingstudy\")\n\ncyclingstudy %&gt;%\n  # Select columns needed for analysis\n  select(subject, group, timepoint, lac.125:lac.375) %&gt;%\n  # Only one participant and time-point\n  filter(timepoint == \"pre\", subject == 3) %&gt;%\n  # Pivot to long format data using the lactate columns\n  pivot_longer(names_to = \"watt\", \n               values_to = \"lactate\", \n               names_prefix = \"lac.\",\n               names_transform = list(watt = as.numeric),\n               cols = lac.225:lac.375) %&gt;%\n  # Plot the data, group = subject needed to connect the points\n  ggplot(aes(watt, lactate, group = subject))  + \n  geom_line(lty = 2) +\n  geom_point(shape = 23, fill = \"pink\", size = 2) +\n  # Adding straight lines at specific values\n geom_hline(yintercept = 4, color = \"blue\") +\n  geom_vline(xintercept = 312, color = \"blue\") + \n   labs(caption = \"Figure 2.3: Estimated exercise intensity at 4 mmol L^-1^ \")\n\nWarning: Removed 2 rows containing missing values (`geom_line()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n #| warning: FALSE\n#| message: FALSE\n#| code-fold: true\n#| name: \"figure 2.4\"\n\ncyclingstudy %&gt;%\n  # Select columns needed for analysis\n  select(subject, group, timepoint, lac.225:lac.375) %&gt;%\n  # Only one participant and time-point\n  filter(timepoint == \"pre\", subject == 3) %&gt;%\n  # Pivot to long format data using the lactate columns\n  pivot_longer(names_to = \"watt\", \n               values_to = \"lactate\", \n               names_prefix = \"lac.\",\n               names_transform = list(watt = as.numeric),\n               cols = lac.225:lac.375) %&gt;%\n  # Plot the data, group = subject needed to connect the points\n  ggplot(aes(watt, lactate, group = subject))  + \n  geom_line(lty = 2) +\n  geom_point(shape = 23, fill = \"pink\", size = 3) +\n   geom_hline(yintercept = 2, color = \"deepskyblue\") +\n  geom_vline(xintercept = 273.3, color = \"deepskyblue\") + \n  geom_hline(yintercept = 4, color = \"blue\") +\n  geom_vline(xintercept = 312, color = \"blue\") +\n  labs(caption = \"Figure 2.4: Curve-linear relationships between exercise intensity and blood lactate\") + \n  # Adding a straight line from a linear model\n  geom_smooth(method = \"lm\", se = FALSE, formula = y ~ x, color = \"azure4\") +\n  \n  # Adding a polynomial linear model to the plot\n  \n  # poly(x, 2) add a second degree polynomial model.\n  geom_smooth(method = \"lm\", se = FALSE, formula = y ~ poly(x, 2), color = \"orange\") +\n  # poly(x, 3) add a third degree polynomial model.\n  geom_smooth(method = \"lm\", se = FALSE, formula = y ~ poly(x, 3), color = \"#4daf4a\") +\n  # poly(x, 4) add a forth degree polynomial model.\n  geom_smooth(method = \"lm\", se = FALSE, formula = y ~ poly(x, 4), color = \"deeppink\") \n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\nRemoved 2 rows containing non-finite values (`stat_smooth()`).\nRemoved 2 rows containing non-finite values (`stat_smooth()`).\nRemoved 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_line()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\nCode\nlactate &lt;- cyclingstudy %&gt;%\n  # Select columns needed for analysis\n  select(subject, group, timepoint, lac.125:lac.375) %&gt;%\n  # Only one participant and time-point\n  filter(timepoint == \"pre\", subject == 3) %&gt;%\n  # Pivot to long format data using the lactate columns\n  pivot_longer(names_to = \"watt\", \n               values_to = \"lactate\", \n               names_prefix = \"lac.\",\n               names_transform = list(watt = as.numeric),\n               cols = lac.125:lac.375) %&gt;%\n  # Remove NA (missing) values to avoid warning/error messages.\n  filter(!is.na(lactate))\n\n# fit \"straight line\" model\nm1 &lt;- lm(lactate ~ watt, data = lactate)\n\n# fit second degree polynomial\nm2 &lt;- lm(lactate ~ poly(watt, 2, raw = TRUE), data = lactate)\n\n# fit third degree polynomial\nm3 &lt;- lm(lactate ~ poly(watt, 3, raw = TRUE), data = lactate)\n\n# fit forth degree polynomial\nm4 &lt;- lm(lactate ~ poly(watt, 4, raw = TRUE), data = lactate)\n\n# Store all residuals as new variables\nlactate$resid.m1 &lt;- resid(m1)\nlactate$resid.m2 &lt;- resid(m2)\nlactate$resid.m3 &lt;- resid(m3)\nlactate$resid.m4 &lt;- resid(m4)\n\nlactate %&gt;%\n  # gather all the data from the models\n  pivot_longer(names_to = \"model\", \n               values_to = \"residual\", \n               names_prefix = \"resid.\", \n               names_transform = list(residual = as.numeric),\n               cols = resid.m1:resid.m4) %&gt;%  \n\n# Plot values with the observed watt on x axis and residual values at the y\n  ggplot(aes(watt, residual, fill = model)) + geom_point(shape = 21, size = 3) +\n  labs(caption = \"Figure 2.5: Assessing the fit of different linear models\") +\n  \n  # To set the same colors/fills as above we use scale fill manual\n  scale_fill_manual(values = c(\"azure4\", \"orange\", \"#4daf4a\", \"deeppink\"))\n\n\n\n\n\n\n\n\n\n\n\nCode\nndf &lt;- data.frame(watt = seq(from = 225, to = 350, by = 0.1)) \n\nndf$predictions &lt;- predict(m3, newdata = ndf)\n\n\nlactate_threshold_2 &lt;- ndf %&gt;%\n  filter(abs(predictions - 2) == min(abs(predictions - 2))) %&gt;% print()\n\n\n   watt predictions\n1 271.8    1.999125\n\n\nCode\nlactate_threshold_4 &lt;- ndf %&gt;%\n  filter(abs(predictions - 4) == min(abs(predictions - 4))) %&gt;% print()\n\n\n   watt predictions\n1 314.2    3.998828\n\n\nVi har kalkulert blodlaktatterskel ved 4mmol L-1 til å være 343 watt, og blodlaktatterskel ved 2mmol L-1 til å være 307 watt for subject “10” ved timepoint “pre”.\n\n\n3.3.2 Del 2: Predikert hellning på qPCR kalibreringskurve\n\n\nCode\nladder &lt;- data.frame(dist = c(408, 430.5, 462.5, 494.5, 536.5, 588.5, 646.5,\n                              730.5, 772.5, 824.5, 888.5, 960.5, 1050.5),\n                     \n                     mw = c(1000, 900, 800, 700, 600, 500, 400, 300, 250, 200, \n                            150, 100, 50))\n\nunknown &lt;- data.frame(dist = c(700.5, 704.5, 702.5, 704.5, 708.5))\n\n\n  cal &lt;- lm(log(mw) ~ dist, data = ladder)\nsummary(cal)\n\n\n\nCall:\nlm(formula = log(mw) ~ dist, data = ladder)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.297886 -0.049183  0.008952  0.105370  0.120330 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  8.7189936  0.1153992   75.56 2.72e-16 ***\ndist        -0.0042923  0.0001633  -26.28 2.81e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.12 on 11 degrees of freedom\nMultiple R-squared:  0.9843,    Adjusted R-squared:  0.9829 \nF-statistic: 690.5 on 1 and 11 DF,  p-value: 2.811e-11\n\n\nCode\npreds &lt;- exp(predict(cal, newdata = unknown))\n\nunknown$preds &lt;- preds\n\nunknown\n\n\n   dist    preds\n1 700.5 302.5425\n2 704.5 297.3924\n3 702.5 299.9564\n4 704.5 297.3924\n5 708.5 292.3300\n\n\nCode\n  plot(ladder$dist, ladder$mw, log = \"y\", pch = 16, col = \"blue\",\n       xlab = \"distance\", ylab = \"molecular weight\", \n       main = \"Figure 2.6: Distance vs. Molecular weight\") \n  lines(ladder$dist, exp(fitted(cal)), col = \"black\")\n  points(unknown$dist, preds, pch = 17, col = \"green\")\n  legend(\"topright\", legend = c(\"ladder\", \"calibration\", \"unknown preds\"),\n       col = c(\"blue\", \"black\", \"green\"), pch = c(16, NA, 17), lty = c(NA, 1, NA))\n\n\n\n\n\n\n\n\n\nKalibreringsmodellen beskriver forholdet mellom avstand og molekylvekt. Etter log-transformering av molekylvekten, blir forholdet mellom avstand og molekylvekt tilnærmet lineært, noe som gjør den lineære regresjonsmodellen passende. R-kvadratverdien på 0.98 indikerer hvor godt modellen passer til dataene da den er tilnærmet 1. De forutsagte molekylvektene for de ukjente prøvene er basert på den tilpassede kalibreringsmodellen. Predikasjonene for de ukjente prøvene gir et estimat av deres molekylvekt basert på deres migrasjonsavstand i gelen. QQ-plottet forteller oss om forskjellene mellom observert og predikert molekylvekt følger en normalfordeling. Ideelt sett bør punktene i QQ-plottet falle langs referanselinjen noe de tilsynelatende gjør. Det vil si at modellen er godt spesifisert, og fanger forholdet mellom migrasjonsavstand og molekylvekt.\n\n\n3.3.3 Del 3: Tolke en regresjonstabell\n\n\nCode\nlibrary(exscidata)\nlibrary(tidyverse)\nlibrary(gt)\n\n\n\ndat &lt;- hypertrophy %&gt;%\n  select(PARTICIPANT, GROUP, FAST_CSA_T1, SQUAT_3RM) %&gt;%\n  print()\n\n\n# A tibble: 31 × 4\n   PARTICIPANT GROUP FAST_CSA_T1 SQUAT_3RM\n   &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;\n 1 MRV001      WP          4629.       152\n 2 MRV002      WP          4939.       125\n 3 MRV003      GWP         3940.       143\n 4 MRV004      GWP         4741.       134\n 5 MRV005      MALTO       3207.       138\n 6 MRV006      WP          5771.       147\n 7 MRV007      WP          3144.       134\n 8 MRV009      GWP         5829.       166\n 9 MRV010      MALTO       4875.       129\n10 MRV011      MALTO       3461.       143\n# ℹ 21 more rows\n\n\nCode\nmodel &lt;- lm(FAST_CSA_T1 ~ SQUAT_3RM, dat) \n\nsummary(model)\n\n\n\nCall:\nlm(formula = FAST_CSA_T1 ~ SQUAT_3RM, data = dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1174.9  -690.9  -208.4   571.0  1657.5 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept) 3382.485   1066.007   3.173  0.00365 **\nSQUAT_3RM      5.483      8.032   0.683  0.50039   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 843.3 on 28 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  0.01637,   Adjusted R-squared:  -0.01875 \nF-statistic: 0.4661 on 1 and 28 DF,  p-value: 0.5004\n\n\nPer økning i kilo SQUAT_3RM øker FAST_CSA_T1 med 5.483m2. Standardfeil (SE) = 8.032. SE forklarer gjennomsnittlig variasjon i økning i populajsjonen tatt fra vårt utvalg. T-verdi = 0.683. T-verdien er relativt lav og indikerer at differansen mellom gjennomsnittet i dataen og gjennomsnittet i populasjonen sannsynligvis er liten. P-verdi = 0.50. P-verdien her tilsier at det ikke er noe signifikant sammenheng mellom økning i kilo i SQUAT_3RM og økning i mikrometer2 i FAST_CSA_T1.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rapport 2</span>"
    ]
  },
  {
    "objectID": "02-regression-models.html#diskusjon",
    "href": "02-regression-models.html#diskusjon",
    "title": "2  Rapport 2",
    "section": "3.4 Diskusjon",
    "text": "3.4 Diskusjon\n\n3.4.1 Diskusjon - del 1\nRapporten viser hvordan man kan kalkulere seg fram til wattbelastning på sykkel ved bestemte laktatverdier på 2 og 4 mmol L-1 som beskriver intensiteten. Vi kom fram til at terskelwatten ved 2 mmol L-1 var 307, og at terskelwatten ved 4mmol L-1 var 343 for subject “10” ved timepoint “pre”.\n\n\n3.4.2 Diskusjon - del 2\nKalibreringsmodellen viser seg å være effektiv til å beskrive forholdet mellom avstand og molekylvekt, spesielt etter at molekylvekten ble log-transformert. Denne transformasjonen bidro til å gjøre forholdet tilnærmet lineær, noe som bekrefter at en lineær regresjonsmodell er en passende tilnærming. Med en R-kvadratverdi på 0.98 ser vi at modellen gir en nesten perfekt tilpasning til dataene, som styrer modellens prediksjonsnøyaktighet. For de ukjente prøvene baseres prediksjonene av molekylvekt på modellen og gir troverdige estimater basert på migrasjonsavstand i gelen. QQ-plottet støtter også modellens robusthet, ettersom punktene faller nær referanselinjen, som indikerer at restene følger en normalfordeling. Dette antyder at modellen er godt spesifisert og gir en pålitelig beskrivelse av sammenhengen mellom migrasjonsavstand og molekylvekt. Samlet bekrefter resultatene at den utviklede modellen fanger opp de sentrale aspektene ved dataene på en god måte.\n\n\n3.4.3 Diskusjon - del 3\nResultatene viser at det er en økning på 5.48 mikrometer2 i FAST_CSA_T1 for hver kilo økning i SQUAT_3RM, men P-verdien på 0.50 indikerer at denne sammenhengen ikke er statistisk signifikant. Standardfeilen (SE) på 8.032 reflekterer variasjonen i estimatet og hvor mye det kan forventes å avvike fra populasjonsgjennomsnittet i utvalget vårt. Den lave t-verdien på 0.683 understøtter også at forskjellen mellom gjennomsnittet i utvalget og populasjonen sannsynligvis er liten. Oppsummert tyder disse funnene på at det ikke er en sterk eller signifikant sammenheng mellom økning i SQUAT_3RM og økning i FAST_CSA_T1. Samtidig som den observerte økningen i FAST_CSA _T1 heller kan være påvirket av tilfeldige variasjoner enn en systematisk effekt av økt styrke.\nPart 2: Predicting sizes of DNA fragments Part 3: Interpreting a regression table\n\n\n\n\nHaun, Cody T, Christopher G Vann, C Brooks Mobley, Shelby C Osburn, Petey W Mumford, Paul A Roberson, Matthew A Romero, et al. 2019. “Pre-Training Skeletal Muscle Fiber Size and Predominant Fiber Type Best Predict Hypertrophic Responses to 6 Weeks of Resistance Training in Previously Trained Young Men.” Front. Physiol. 10 (March): 297.\n\n\nHaun, Cody T, Christopher G Vann, Christopher B Mobley, Paul A Roberson, Shelby C Osburn, Hudson M Holmes, Petey M Mumford, et al. 2018. “Effects of Graded Whey Supplementation During Extreme-Volume Resistance Training.” Front. Nutr. 5 (September): 84.\n\n\n“Login - eLabFTW — Elab.inn.no.” https://elab.inn.no/experiments.php?mode=view&id=83.\n\n\nPosit team. 2024. RStudio: Integrated Development Environment for r. Boston, MA: Posit Software, PBC. http://www.posit.co/.\n\n\nSchindelin, Johannes, Ignacio Arganda-Carreras, Erwin Frise, Verena Kaynig, Mark Longair, Tobias Pietzsch, Stephan Preibisch, et al. 2012. “Fiji: An Open-Source Platform for Biological-Image Analysis.” Nat. Methods 9 (7): 676–82.\n\n\nSylta, Øystein, Espen Tønnessen, Daniel Hammarström, Jørgen Danielsen, Knut Skovereng, Troels Ravn, Bent R Rønnestad, Øyvind Sandbakk, and Stephen Seiler. 2016. “The Effect of Different High-Intensity Periodization Models on Endurance Adaptations.” Med. Sci. Sports Exerc. 48 (11): 2165–74.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Rapport 2</span>"
    ]
  },
  {
    "objectID": "01-reliability-tools.html",
    "href": "01-reliability-tools.html",
    "title": "1  Assignment 1: Reliability and tools for reproducible data science",
    "section": "",
    "text": "1.1 Method",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Assignment 1: Reliability and tools for reproducible data science</span>"
    ]
  },
  {
    "objectID": "01-reliability-tools.html#method",
    "href": "01-reliability-tools.html#method",
    "title": "1  Assignment 1: Reliability and tools for reproducible data science",
    "section": "",
    "text": "1.1.1 Standardization pre-test\nSame workout regime two days before test day.\nFood intake and hydration + caffeine - last two meals should be the same\nsleep - same sleeping schedule\nsame test time for each test\n(halperin2015?).\n\n\n1.1.2 Protocol",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Assignment 1: Reliability and tools for reproducible data science</span>"
    ]
  },
  {
    "objectID": "01-reliability-tools.html#results",
    "href": "01-reliability-tools.html#results",
    "title": "1  Assignment 1: Reliability and tools for reproducible data science",
    "section": "1.2 Results",
    "text": "1.2 Results\n\n1.2.1 Figur 1\n\n\n\n\n\n\n\n\n\nFigur 1 viser det absolutte maksimale oksygenopptaket til hver enkelt deltaker, sammenlignet med alle testene som ble gjennomført til alle deltakerne.\n\n\n1.2.2 Tabell 1\n\n\n\n\n\n\n\n\nid\nt1\nt2\nt3\nt4\n\n\n\n\nG1_id1\n3381.5\n3065.0\n3190.0\n3343.0\n\n\nG1_id2\n2771.0\n2801.5\n2464.5\n2760.0\n\n\nG1_id3\n4234.5\n4235.0\n3693.5\n4361.0\n\n\nG2_4\nNA\nNA\n2819.5\n2893.0\n\n\nG2_5\n4427.0\n4359.5\nNA\nNA\n\n\nG2_6\n3704.5\n3713.5\nNA\nNA\n\n\nG2_7\n5116.5\n5163.5\n4951.0\n5294.5\n\n\nG2_8\nNA\nNA\nNA\n2543.5\n\n\nG3_9\n4694.0\n4640.5\n4614.0\nNA\n\n\nG3_10\n3014.5\n3103.5\n3170.5\n3093.0\n\n\nG3_11\n3576.5\n3713.0\nNA\nNA\n\n\nG3_12\n4332.5\n4362.0\n4737.0\nNA\n\n\nG4_id13\n4634.5\n4606.5\n4540.5\nNA\n\n\nG4_id14\n4556.5\n4561.5\n4437.0\n4545.0\n\n\nG4_id15\n4350.5\n3818.5\n4134.0\nNA\n\n\nG4_id16\n4872.0\n5050.0\nNA\nNA\n\n\n\n\n\n\n\nTabell 1 viser det samme som “Figur 1”, men her kan man lettere se hvor mange tester hver enkelt deltaker har gjennomført og hvilket resultat som hører til hvilken test.\n\n\n1.2.3 Tabellen eg skal bruke\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(gt)\n\n# Reshape data and calculate differences between timepoints\ndat_wide &lt;- dat %&gt;%\n  select(id, timepoint, vo2.max) %&gt;%\n  pivot_wider(names_from = timepoint, values_from = vo2.max) %&gt;%\n  mutate(Diff_T2_T1 = `t2` - `t1`,\n         Diff_T4_T3 = `t4` - `t3`) \n\n# Create summary table with n for each timepoint\nn_summary &lt;- dat %&gt;%\n  group_by(timepoint) %&gt;%\n  summarise(n = n())\n\n# Generate table with gt\ndat_wide %&gt;%\n  gt() %&gt;%\n  tab_header(\n    title = \"VO2max per Participant per Timepoint\"\n  ) %&gt;%\n  cols_label(\n    id = \"Participant ID\",\n    `t1` = \"Test 1\",\n    `t2` = \"Test 2\",\n    `t3` = \"Test 3\",\n    `t4` = \"Test 4\",\n    Diff_T2_T1 = \"Difference (T2 - T1)\",\n    Diff_T4_T3 = \"Difference (T4 - T3)\"\n  ) %&gt;%\n  fmt_number(\n    columns = everything(),\n    decimals = 2\n  ) %&gt;%\n  tab_footnote(\n    footnote = paste(\"Sample sizes: t1 = \", n_summary$n[1], \n                     \", t2 = \", n_summary$n[2], \n                     \", t3 = \", n_summary$n[3], \n                     \", t4 = \", n_summary$n[4])\n  )\n\n\n\n\n\n\n\nVO2max per Participant per Timepoint\n\n\nParticipant ID\nTest 1\nTest 2\nTest 3\nTest 4\nDifference (T2 - T1)\nDifference (T4 - T3)\n\n\n\n\nG1_id1\n3,381.50\n3,065.00\n3,190.00\n3,343.00\n−316.50\n153.00\n\n\nG1_id2\n2,771.00\n2,801.50\n2,464.50\n2,760.00\n30.50\n295.50\n\n\nG1_id3\n4,234.50\n4,235.00\n3,693.50\n4,361.00\n0.50\n667.50\n\n\nG2_4\nNA\nNA\n2,819.50\n2,893.00\nNA\n73.50\n\n\nG2_5\n4,427.00\n4,359.50\nNA\nNA\n−67.50\nNA\n\n\nG2_6\n3,704.50\n3,713.50\nNA\nNA\n9.00\nNA\n\n\nG2_7\n5,116.50\n5,163.50\n4,951.00\n5,294.50\n47.00\n343.50\n\n\nG2_8\nNA\nNA\nNA\n2,543.50\nNA\nNA\n\n\nG3_9\n4,694.00\n4,640.50\n4,614.00\nNA\n−53.50\nNA\n\n\nG3_10\n3,014.50\n3,103.50\n3,170.50\n3,093.00\n89.00\n−77.50\n\n\nG3_11\n3,576.50\n3,713.00\nNA\nNA\n136.50\nNA\n\n\nG3_12\n4,332.50\n4,362.00\n4,737.00\nNA\n29.50\nNA\n\n\nG4_id13\n4,634.50\n4,606.50\n4,540.50\nNA\n−28.00\nNA\n\n\nG4_id14\n4,556.50\n4,561.50\n4,437.00\n4,545.00\n5.00\n108.00\n\n\nG4_id15\n4,350.50\n3,818.50\n4,134.00\nNA\n−532.00\nNA\n\n\nG4_id16\n4,872.00\n5,050.00\nNA\nNA\n178.00\nNA\n\n\n\nSample sizes: t1 = 14 , t2 = 14 , t3 = 11 , t4 = 8\n\n\n\n\n\n\n\n\n\n\n1.2.4 Beregning av standardfeil mellom test 1 og test 2\n\n\n\n\n\n\n\n\nmean\nsd\nte\ncv\n\n\n\n\n4,102.1\n183.5\n129.8\n3.2\n\n\n\n\n\n\n\n\n\n1.2.5 Beregning av standardfeil mellom test 3 og test 4\n\n\n\n\n\n\n\n\nmean\nsd\nte\ncv\n\n\n\n\n4,102.1\n240.9\n170.3\n4.2\n\n\n\n\n\n\n\nWe calculated that the\nVi kalkulerte at variasjonskoeffisienten (CV) for test 1 og test 2 ble 3.16%. I følge Dr. Will G. Hopkins indikerer en variasjonskoeffisient (CV) på under 5% god reliabilitet (hopkins2000a?). Det vil si at resultatene for test 1 og test 2 har relativt lav variabilitet og bør betraktes som reliable. For test 3 og test 4 kalkulerte vi at variasjonskoeffisienten (CV) ble 4.2%. Det vil si at også resultatene for test 3 og test 4 kan betraktes som reliable, men har mer variabilitet enn resultatene fra test 1 og test 2 da variasjonskoeffisienten er noe høyere.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Assignment 1: Reliability and tools for reproducible data science</span>"
    ]
  },
  {
    "objectID": "01-reliability-tools.html#discussion",
    "href": "01-reliability-tools.html#discussion",
    "title": "1  Assignment 1: Reliability and tools for reproducible data science",
    "section": "1.3 Discussion",
    "text": "1.3 Discussion\n\n1.3.1 Deviance (avvik?)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Assignment 1: Reliability and tools for reproducible data science</span>"
    ]
  },
  {
    "objectID": "01-reliability-tools.html#conclusion",
    "href": "01-reliability-tools.html#conclusion",
    "title": "1  Assignment 1: Reliability and tools for reproducible data science",
    "section": "1.4 Conclusion",
    "text": "1.4 Conclusion",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Assignment 1: Reliability and tools for reproducible data science</span>"
    ]
  },
  {
    "objectID": "04-study-design.html",
    "href": "04-study-design.html",
    "title": "4  Study designs",
    "section": "",
    "text": "4.1 Introduction\nA good study design is crucial for producing reliable and meaningful research results. It minimizes bias and ensures that the results are valid, reproducible and generalizable. In this report we’ve analyzed the study design of five original research studies who tried to understand the association between menstrual cycle and musculoskeletal injury among female athletes. We describe strength and weaknesses of each study and comment on the selection of statistical tests to answer study aims. Lastly, recommendations are given regarding how future studies in this area should be designed to best answer similar questions.\nThe broader problem the authors are trying to resolve is similar in each study, but the specific questions they are trying to answer is angled differently. Chang et al. investigates the prevalence and relationship between hormonal contraceptive use, menstrual function and stress fractures in female collegiate athletes in the United States (Cheng et al. 2021). Bingzheng et al. is also focusing on female collegiate athletes but limits it down to just soccer players. Their study aims to examine how the menstrual cycle and sex hormones affect knee kinematics, specifically during a 90-degree cutting maneuver (Bingzheng et al. 2023). Female soccer players are also the population of the study done by Martin et al., specifically English national team players, as they aimed to enhance the understanding of how the menstrual cycle, including extended cycle length, may impact injury risk in said population (Martin et al. 2021). On the other hand, Ackerman et al. studied younger female athletes and investigated whether there is a difference in fracture occurrence between oligoamenorrheic athletes (AA), eumenorrheic athletes (EA), and nonathletes (NA). The study also tried to determine the relationship between bone density, structure, and strength estimates (Ackerman et al. 2015). The last study, done by Thein-Nissenbaum et al., investigates the prevalence of and the relationship between menstrual irregularity and musculoskeletal injuries in female high school athletes (Thein-Nissenbaum et al. 2012).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Study designs</span>"
    ]
  },
  {
    "objectID": "04-study-design.html#introduction",
    "href": "04-study-design.html#introduction",
    "title": "4  Study designs",
    "section": "5.1 Introduction",
    "text": "5.1 Introduction\nA good study design is crucial for producing reliable and meaningful research results. It minimizes bias and ensures that the results are valid, reproducible and generalizable. In this report we’ve analyzed the study design of five original research studies who tried to understand the association between menstrual cycle and musculoskeletal injury among female athletes. We describe strength and weaknesses of each study and comment on the selection of statistical tests to answer study aims. Lastly, recommendations are given regarding how future studies in this area should be designed to best answer similar questions.\nThe broader problem the authors are trying to resolve is similar in each study, but the specific questions they are trying to answer is angled differently. Chang et al. investigates the prevalence and relationship between hormonal contraceptive use, menstrual function and stress fractures in female collegiate athletes in the United States (Cheng et al. 2021). Bingzheng et al. is also focusing on female collegiate athletes but limits it down to just soccer players. Their study aims to examine how the menstrual cycle and sex hormones affect knee kinematics, specifically during a 90-degree cutting maneuver (Bingzheng et al. 2023). Female soccer players are also the population of the study done by Martin et al., specifically English national team players, as they aimed to enhance the understanding of how the menstrual cycle, including extended cycle length, may impact injury risk in said population (Martin et al. 2021). On the other hand, Ackerman et al. studied younger female athletes and investigated whether there is a difference in fracture occurrence between oligoamenorrheic athletes (AA), eumenorrheic athletes (EA), and nonathletes (NA). The study also tried to determine the relationship between bone density, structure, and strength estimates (Ackerman et al. 2015). The last study, done by Thein-Nissenbaum et al., investigates the prevalence of and the relationship between menstrual irregularity and musculoskeletal injuries in female high school athletes (Thein-Nissenbaum et al. 2012).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Study designs</span>"
    ]
  },
  {
    "objectID": "04-study-design.html#study-designs",
    "href": "04-study-design.html#study-designs",
    "title": "4  Study designs",
    "section": "4.2 Study designs",
    "text": "4.2 Study designs\nOne factor all the studies have in common is that they use an observational study design. Observational studies have two primary purposes: descriptive where one examines the distributions of predictors and outcomes in a population, and analytic where one characterizes associations between these predictor and outcome variables (Hulley et al. 2013). Most of the studies are cross-sectional studies as the investigators makes all the measurements on a single occasion or within a short period of time. Cross-sectional studies provide info about prevalence and can be used for examining associations (Hulley et al. 2013). For instance, in the study done by Ackerman et al., data from different groups of participants were collected within the same day. They interviewed participants to document previous fractures, then measured areal bone mass index of the spine, hip and whole body as well as assessing bone structure. In contrast, the study done by Bingzheng et al. is also an observational study, but a cohort study as the measurements take place over a period of time. They measured sex hormones and analyzed knee kinematics of the participants during four different phases of the menstrual cycle. More specifically is this a prospective cohort study as the participants are followed over time to observe outcomes that occur after the study begins (Hulley et al. 2013). This way of doing a study may be more beneficial than a cross-sectional study as it allows the calculation of incidence. On the other hand, the study done by Martin et al. where they tried to find the association between menstrual cycle and injury risk in female soccer players, can be classified as a case series study design. They recorded injuries and menstrual irregularities among English national soccer team players over a period of four years. Here the group of individuals all share a specific characteristic, they are tracked over a defined period and the outcome in the group is documented. Unlike cohort studies, a case series lacks a comparison group, meaning it does not compare outcomes between exposed and non-exposed individuals or those with and without a condition. This can be seen in the study done by Martin et al. as they gathered data on injury types and menstrual irregularities, but did not include a non-injured or non-menstrual-irregularity group for comparison.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Study designs</span>"
    ]
  },
  {
    "objectID": "04-study-design.html#selection-of-statistical-tests",
    "href": "04-study-design.html#selection-of-statistical-tests",
    "title": "4  Study designs",
    "section": "4.3 Selection of statistical tests",
    "text": "4.3 Selection of statistical tests\nSelecting the appropriate statistical test is crucial for ensuring valid and reliable results. The choice depends on several factors, including the type of data you have, your research question, and the assumptions of the tests. None of the studies provided a detailed description of all the statistical tests used, and the studies varied in how many and what type of statistical tests they used to analyze the data. The study done by Thein-Nissenbaum et al. provided the most detailed description on how the data was analyzed. They used a one-way ANOVA with Bonferroni post hoc test to compare mean values for continuous variables between different sport types. Chi-square tests were used to examine associations between categorical variables, such as menstrual irregularity and sport type. Lastly, they calculated odds ratio (OR) and 95% confidence intervals (CI) to compare injury severity between athletes with and without menstrual irregularities. Another study that reported OR and CI where the study done by Cheng et al. as they investigated the relationship between the different variables in their study. They also used two-sided t-tests to analyze continuous variables and Pearson’s chi-square tests to analyze categorical variables. Moreover, the study done by Ackerman et al. compared three groups (AA, EA and NA) regarding various variables such as fracture prevalence, BMD Z-score, bone structure and strength estimates. The study does not specify exactly which statistical tests were used but mentions using p-values to assess statistical significance. Based on this, and the study’s goal of comparing groups, we can assume they likely used t-tests or ANOVA tests for continuous variables and chi-square tests for categorical variables. Another study that also compared different groups is the one done by Bingzheng et al. where they examine differences between menstrual phase, late follicular phase, ovulation phase and mid-luteal phase. The authors do not explicitly mention which statistical tests they used but we can assume that they likely used an ANOVA test to compare the mean values of knee kinematics parameters between the four groups. To examine the relationship between serum estrogen, progesterone concentrations and knee kinematics parameters, a correlation analysis, such as Pearson’s, were likely used. Lastly, the study done by Martin et al. used a more descriptive approach and did not perform hypothesis testing. Instead, it focused on calculating injury incidence per 1,000 person-days for each menstrual cycle phase and compared injury incidence ratios between the phases. All together, these variations in statistical methods underscore the importance of aligning test selection with research objectives and data characteristics to ensure meaningful results across studies.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Study designs</span>"
    ]
  },
  {
    "objectID": "04-study-design.html#inference",
    "href": "04-study-design.html#inference",
    "title": "4  Study designs",
    "section": "4.4 Inference",
    "text": "4.4 Inference\nThe five studies analyzed in this report each contribute valuable insights into the complex relationship between the menstrual cycle and musculoskeletal injuries among female athletes. The findings highlight the multifaceted nature of this association, with varying conclusions depending on the specific study. For example, one study emphasized that hormonal contraceptive use is common among female athletes and may mask underlying menstrual irregularities, urging more education on this risk (Cheng et al. 2021). Another study noted that sex hormones do not have a protective effect on knee kinematics in female soccer players, suggesting that other factors, such as neuromuscular control, should be explored (Bingzheng et al. 2023). In terms of bone health, a study revealed that while weight-bearing exercise can improve bone mineral density (BMD), it may also increase the risk of stress fractures, especially in athletes with menstrual disorders (Ackerman et al. 2015). The different phases of the menstrual cycle also appeared critical, with a study showing that muscle and tendon injuries might be more likely in the days leading up to ovulation (Martin et al. 2021). Lastly, high prevalence of both menstrual irregularities and musculoskeletal injuries was found among high school athletes, with those experiencing menstrual issues having a higher proportion of severe injuries, suggesting menstrual irregularity as a potential risk factor (Thein-Nissenbaum et al. 2012). These studies collectively underscore the need for further research to clarify the mechanisms at play and develop more tailored prevention strategies.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Study designs</span>"
    ]
  },
  {
    "objectID": "04-study-design.html#strength-and-weakness",
    "href": "04-study-design.html#strength-and-weakness",
    "title": "4  Study designs",
    "section": "4.5 Strength and weakness",
    "text": "4.5 Strength and weakness\nEach study design comes with its own unique strengths and weaknesses. Among the studies we reviewed, three utilized a cross-sectional design, focusing on capturing data at a single point in time to assess associations between variables. A cross-sectional study design can be ideal when the researchers don’t have the time or money to do a longer study as there is no waiting around for the outcome to occur. This makes them fast and inexpensive and avoids the problem of loss to follow-up (Hulley et al. 2013). On the other hand, a cross-sectional study measure only prevalence, rather than incidence, it is therefore important to be cautious when drawing inference about the causes of the condition. A factor that is associated with prevalence of a condition may be a cause of the condition but could also be associated with the duration of the condition (Hulley et al. 2013). In other words, it may be difficult to establish causal relationships from cross-sectional data. A cohort study, unlike a cross-sectional design, allows for the calculation of incidence. Here levels of the predictor are measured before the outcome occurs which establishes the time sequence of the variables and strengthens the process of inferring the causal basis of an association (Hulley et al. 2013). It also prevents the predictor measurements from being influenced by the outcome or knowledge of its occurrence and it allows the investigator to measure variables more completely and accurately than is usually possible retrospectively (Hulley et al. 2013). However, a cohort study is more time consuming and may therefore be expensive. In contrast, a case series study design is relatively easy to conduct and do not require the complexity or cost associated with larger studies, making it simple and inexpensive. The design allows for the collection of meaningful data from a small group of cases, and researchers can generate hypotheses that can later be tested in more controlled studies. However, it does not include a comparison group, making it difficult to establish causal relationships or to compare outcomes against a standard or control. There is also no control over external variables making it impossible to definitively conclude that a particular exposure caused the outcome. Additionally, all the study designs are observational studies meaning that causal inference is challenging, and interpretation is often muddied by the influences of confounding variables (Hulley et al. 2013). It is therefore important to consider this disadvantage when choosing what statistical test to use when analyzing the data.\nIn general, most of the studies have a large sample size which increases the statistical power and gives a better representation of the population in general, meaning that there is a high generalization of the findings. They also had an extensive data collection gathering information on a wide range of variables, such as demographics, sports participation, and hormonal contraceptives, providing a detailed picture of the health status of this population. On the other hand, most of the studies relied on self-reported data about menstrual and injury history, which may lead to inaccurate recall. They also used a subjective approach to measure some of the variables resulting in less accurate and reliable data. Such lack of clinical data makes it hard to verify the results.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Study designs</span>"
    ]
  },
  {
    "objectID": "04-study-design.html#recommendations",
    "href": "04-study-design.html#recommendations",
    "title": "4  Study designs",
    "section": "4.6 Recommendations",
    "text": "4.6 Recommendations\nTo better understand the association between menstrual cycle and musculoskeletal injury among female athletes, future studies should use a prospective study design where a group of individuals are observed over time. The researcher would observe the athlete before the injury occurs to better examine how specific exposures or factors, in this case the menstrual cycle, influence the outcome. Recall bias was one of the weaknesses of the studies we analyzed, a prospective study minimizes recall bias and allows for confounding factors making it highly reliable for establishing causal relationships. Another thing that can be done differently is how the menstrual cycle is measured. A more objective approach would be more reliable as hormonal measurements, or the use of menstrual tracking apps, can provide more precise data. Lastly, one should control for other relevant factors such as training volume, diet, stress levels and the use of birth control as they all can affect the menstrual cycle and frequency of injuries.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Study designs</span>"
    ]
  },
  {
    "objectID": "04-study-design.html#conclusion",
    "href": "04-study-design.html#conclusion",
    "title": "4  Study designs",
    "section": "4.7 Conclusion",
    "text": "4.7 Conclusion\nIn conclusion, our analysis of the five studies highlights both the complexity of the relationship between the menstrual cycle and injuries, as well as the varying approaches taken to study it. While observational study designs were commonly used, each study presented unique strengths and limitations. Cross-sectional studies provided valuable insight into prevalence but struggled with establishing causal relationships, while prospective cohort studies allowed for a clearer understanding of incidence and causality but required more time and resources. Statistical analysis methods varied across studies, with some providing detailed descriptions while others left assumptions to be made about the tests used. Across the board, reliance on self-reported data introduced the risk of recall bias, and the lack of clinical data diminished the reliability of some findings. Future studies would therefore benefit from prospective designs, objective measures of the menstrual cycle, and better control for confounding factors to further clarify the impact of the menstrual cycle on injury risk.\n\n\n\n\nAckerman, Kathryn E, Natalia Cano Sokoloff, Giovana DE Nardo Maffazioli, Hannah M Clarke, Hang Lee, and Madhusmita Misra. 2015. “Fractures in Relation to Menstrual Status and Bone Parameters in Young Athletes.” Med. Sci. Sports Exerc. 47 (8): 1577–86.\n\n\nBingzheng, Zhou, Zhao Xinzhuo, Jin Zhuo, Yang Xing, Li Bin, and Bai Lunhao. 2023. “The Effects of Sex Hormones During the Menstrual Cycle on Knee Kinematics.” Front. Bioeng. Biotechnol. 11 (September): 1209652.\n\n\nCheng, Jennifer, Kristen A Santiago, Zafir Abutalib, Kate E Temme, Ann Hulme, Marci A Goolsby, Carrie L Esopenko, and Ellen K Casey. 2021. “Menstrual Irregularity, Hormonal Contraceptive Use, and Bone Stress Injuries in Collegiate Female Athletes in the United States.” PM R 13 (11): 1207–15.\n\n\nHulley, Stephen B, Steven R Cummings, Warren S Browner, Deborah G Grady, and Thomas B Newman. 2013. Designing Clinical Research. 4th ed. Philadelphia, PA: Lippincott Williams; Wilkins.\n\n\nMartin, Dan, Kate Timmins, Charlotte Cowie, Jon Alty, Ritan Mehta, Alicia Tang, and Ian Varley. 2021. “Injury Incidence Across the Menstrual Cycle in International Footballers.” Front. Sports Act. Living 3 (March): 616999.\n\n\nThein-Nissenbaum, Jill M, Mitchell J Rauh, Kathleen E Carr, Keith J Loud, and Timothy A McGuine. 2012. “Menstrual Irregularity and Musculoskeletal Injury in Female High School Athletes.” J. Athl. Train. 47 (1): 74–82.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Study designs</span>"
    ]
  }
]